import requests
from bs4 import BeautifulSoup
import re
import time
import os
import pandas as pd
from openpyxl.styles import Font, Alignment, Border, Side, PatternFill


# é¢œè‰²ä»£ç å®šä¹‰
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


def print_separator():
    """æ‰“å°åˆ†éš”çº¿ç¾åŒ–è¾“å‡º"""
    print(f"\n{Colors.OKBLUE}" + "=" * 60 + f"{Colors.ENDC}\n")


def create_filename_from_url(url):
    """ä»URLç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ŒåŒ…å«åŸŸåå’Œè·¯å¾„ä¿¡æ¯"""
    # æå–åŸŸåéƒ¨åˆ†
    domain_match = re.search(r'https?://([^/]+)', url)
    if not domain_match:
        return "unknown_domain_unknown_path"

    domain = domain_match.group(1)
    # æ›¿æ¢åŸŸåä¸­çš„ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
    safe_domain = re.sub(r'[^\w]', '_', domain)

    # æå–è·¯å¾„ä¸­çš„æœ€åä¸€éƒ¨åˆ†
    path_parts = url.split('/')[3:]  # è·³è¿‡åè®®å’ŒåŸŸåéƒ¨åˆ†
    # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å¹¶è·å–æœ€åä¸€ä¸ªæœ‰æ•ˆè·¯å¾„æ®µ
    valid_path_parts = [part for part in path_parts if part.strip()]
    last_path = valid_path_parts[-1] if valid_path_parts else "unknown_path"

    # æ›¿æ¢è·¯å¾„ä¸­çš„ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿
    safe_path = re.sub(r'[^\w]', '_', last_path)

    # ç»„åˆåŸŸåå’Œè·¯å¾„éƒ¨åˆ†
    return f"{safe_domain}_{safe_path}"


def get_unique_filename(base_name):
    """ç”Ÿæˆå”¯ä¸€Excelæ–‡ä»¶åï¼Œè‹¥å­˜åœ¨åˆ™æ·»åŠ é€’å¢åºå·"""
    full_base = f"{base_name}_result"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(f"{full_base}.xlsx"):
        return f"{full_base}.xlsx"

    # è‹¥å­˜åœ¨åˆ™æ·»åŠ åºå·
    counter = 1
    while True:
        # æ ¼å¼åŒ–åºå·ä¸ºä¸¤ä½æ•°å­—ï¼ˆ01, 02, ..., 99ï¼‰
        numbered_name = f"{full_base}_{counter:02d}.xlsx"
        if not os.path.exists(numbered_name):
            return numbered_name
        counter += 1
        # é™åˆ¶æœ€å¤§åºå·ï¼Œé¿å…æ— é™å¾ªç¯
        if counter > 99:
            return f"{full_base}_{counter}.xlsx"


def format_excel(file_path):
    """ç¾åŒ–Excelè¡¨æ ¼"""
    # æ‰“å¼€Excelæ–‡ä»¶
    df = pd.read_excel(file_path)
    writer = pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace')
    df.to_excel(writer, index=False, sheet_name='Results')

    # è·å–å·¥ä½œè¡¨
    worksheet = writer.sheets['Results']

    # å®šä¹‰æ ·å¼
    header_font = Font(bold=True, color="FFFFFF")
    header_fill = PatternFill(start_color="4F81BD", end_color="4F81BD", fill_type="solid")
    border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    alignment = Alignment(vertical='center', wrap_text=False)

    # è®¾ç½®è¡¨å¤´æ ·å¼
    for cell in worksheet[1]:  # è¡¨å¤´åœ¨ç¬¬äºŒè¡Œï¼ˆç´¢å¼•1ï¼‰
        cell.font = header_font
        cell.fill = header_fill
        cell.border = border
        cell.alignment = alignment

    # è®¾ç½®æ•°æ®å•å…ƒæ ¼æ ·å¼å’Œåˆ—å®½
    for row in worksheet.iter_rows(min_row=2):
        for cell in row:
            cell.border = border
            cell.alignment = alignment

    # ç‰¹æ®Šè®¾ç½®åºå·åˆ—å±…ä¸­æ˜¾ç¤º
    if 'åºå·' in [cell.value for cell in worksheet[1]]:
        index_col = [cell.value for cell in worksheet[1]].index('åºå·')
        index_letter = worksheet.cell(row=1, column=index_col + 1).column_letter
        for cell in worksheet[index_letter]:
            cell.alignment = Alignment(horizontal='center', vertical='center')

    # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
    for column_cells in worksheet.columns:
        length = max(len(str(cell.value)) for cell in column_cells) + 2
        worksheet.column_dimensions[column_cells[0].column_letter].width = min(length, 50)  # æœ€å¤§å®½åº¦é™åˆ¶

    writer.close()


def extract_and_process():
    # ç¾åŒ–æ¬¢è¿ç•Œé¢
    print(f"\n{Colors.HEADER}" + "*" * 60)
    print(" " * 15 + "URLæ ‡ç­¾æå–ä¸Excelç”Ÿæˆå·¥å…· v1.0")
    print("*" * 60 + f"{Colors.ENDC}")

    # è·å–ç”¨æˆ·è¾“å…¥çš„URL
    url = input(f"\n{Colors.BOLD}è¯·è¾“å…¥è¦è®¿é—®çš„URL: {Colors.ENDC}").strip()

    # æ˜¾ç¤ºå¤„ç†ä¸­çŠ¶æ€
    print(f"\n{Colors.OKBLUE}æ­£åœ¨å¤„ç†ï¼Œè¯·ç¨å€™...{Colors.ENDC}", end="", flush=True)

    try:
        # å‘é€è¯·æ±‚è®¿é—®URL
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ

        # è§£æXMLå†…å®¹
        soup = BeautifulSoup(response.text, 'xml')

        # æå–æ‰€æœ‰Keyæ ‡ç­¾çš„å†…å®¹ - ä½œä¸ºä¸»è¦æ•°æ®åˆ—è¡¨
        key_tags = soup.find_all('Key')
        if not key_tags:
            print("\r" + " " * 30 + "\r", end="")  # æ¸…é™¤"å¤„ç†ä¸­"æç¤º
            print_separator()
            print(f"{Colors.WARNING}âš ï¸  æœªæ‰¾åˆ°ä»»ä½•<Key>æ ‡ç­¾å†…å®¹{Colors.ENDC}")
            print_separator()
            return

        # è¦æå–çš„æ ‡ç­¾åˆ—è¡¨
        tags_to_extract = ['Key', 'Size', 'Type', 'ID', 'LastModified']

        # æ”¶é›†æ‰€æœ‰æ•°æ®
        data = []
        total_items = len(key_tags)

        # åŸºç¡€URLç”¨äºæ‹¼æ¥å®Œæ•´é“¾æ¥
        base_url_match = re.search(r'(https?://[^/]+/)', url)
        base_url = base_url_match.group(1) if base_url_match else ""

        for i, key_tag in enumerate(key_tags):
            # è¿›åº¦æç¤º
            progress = (i + 1) / total_items * 100
            print(f"\r{Colors.OKBLUE}æ­£åœ¨å¤„ç†: {progress:.1f}%{Colors.ENDC}", end="", flush=True)

            item = {}
            # æ·»åŠ åºå·åˆ—ï¼ˆä»1å¼€å§‹ï¼‰
            item['åºå·'] = i + 1

            # æå–Keyå†…å®¹
            item['Key'] = key_tag.get_text(strip=True)

            # ç”Ÿæˆå®Œæ•´é“¾æ¥ä½œä¸ºHost
            item['Host'] = f"{base_url}{item['Key']}" if base_url else item['Key']

            # æå–å…¶ä»–æ ‡ç­¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            for tag in tags_to_extract[1:]:  # è·³è¿‡å·²ç»å¤„ç†çš„Key
                # å°è¯•æŸ¥æ‰¾å½“å‰Keyæ ‡ç­¾åçš„åŒçº§æ ‡ç­¾
                tag_element = key_tag.find_next_sibling(tag)
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æŸ¥æ‰¾
                if not tag_element:
                    tag_element = soup.find(tag)
                if tag_element:
                    item[tag] = tag_element.get_text(strip=True)

            data.append(item)

        # ç”ŸæˆåŸºç¡€æ–‡ä»¶åï¼ˆåŒ…å«åŸŸåå’Œè·¯å¾„ä¿¡æ¯ï¼‰
        base_filename = create_filename_from_url(url)

        # è·å–å”¯ä¸€Excelæ–‡ä»¶å
        excel_filename = get_unique_filename(base_filename)

        # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºExcel
        df = pd.DataFrame(data)
        # ç¡®ä¿åºå·åˆ—åœ¨æœ€å‰é¢
        if 'åºå·' in df.columns:
            cols = ['åºå·'] + [col for col in df.columns if col != 'åºå·']
            df = df[cols]

        df.to_excel(excel_filename, index=False, sheet_name='Results')

        # ç¾åŒ–Excelè¡¨æ ¼
        format_excel(excel_filename)

        # ç¾åŒ–è¾“å‡ºç»“æœ
        print("\r" + " " * 30 + "\r", end="")  # æ¸…é™¤è¿›åº¦æç¤º
        print_separator()
        print(f"{Colors.OKGREEN}âœ…  å¤„ç†å®Œæˆï¼{Colors.ENDC}")
        print(f"{Colors.BOLD}" + "-" * 40 + f"{Colors.ENDC}")
        print(f"ğŸ“Š  ç»“æœå·²ä¿å­˜è‡³ï¼š{Colors.UNDERLINE}{excel_filename}{Colors.ENDC}")
        print(f"{Colors.BOLD}" + "-" * 40 + f"{Colors.ENDC}")

        # æ˜¾ç¤ºæå–çš„åˆ—ä¿¡æ¯
        columns_info = f"æå–çš„åˆ—: {', '.join(df.columns.tolist())}"
        print(f"{Colors.OKBLUE}{columns_info}{Colors.ENDC}")
        print(f"{Colors.OKBLUE}ğŸ“Š  ç»Ÿè®¡ä¿¡æ¯ï¼šå…±æå– {total_items} æ¡è®°å½•{Colors.ENDC}")
        print_separator()

    except requests.exceptions.RequestException as e:
        print("\r" + " " * 30 + "\r", end="")  # æ¸…é™¤è¿›åº¦æç¤º
        print_separator()
        print(f"{Colors.FAIL}âŒ  è®¿é—®URLæ—¶å‡ºé”™: {str(e)[:50]}...{Colors.ENDC}")
        print_separator()
    except Exception as e:
        print("\r" + " " * 30 + "\r", end="")  # æ¸…é™¤è¿›åº¦æç¤º
        print_separator()
        print(f"{Colors.FAIL}âŒ  å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)[:50]}...{Colors.ENDC}")
        print_separator()


if __name__ == "__main__":
    extract_and_process()
